{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flyer Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "state_prime is next state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tqdm\n",
    "# ! pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import gym\n",
    "import tqdm\n",
    "\n",
    "import Flyer_Agent_Environment as FAE\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "#%matplotlib inline \n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_naive_returns(rewards):\n",
    "    \"\"\" Calculates a list of naive returns given a \n",
    "    list of rewards.\"\"\"\n",
    "    total_returns = np.zeros(len(rewards))\n",
    "    total_return = 0.0\n",
    "    for t in range(len(rewards), -1, -1): # changed end index to -1 RL\n",
    "        total_return = total_return + rewards[t] # also fixed\n",
    "        total_returns[t] = total_return\n",
    "    return total_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, gamma=0.99):\n",
    "    discounted_returns = [0 for _ in rewards]\n",
    "    discounted_returns[-1] = rewards[-1]\n",
    "    for t in range(len(rewards)-2, -1, -1): # iterate backwards\n",
    "        discounted_returns[t] = rewards[t] + discounted_returns[t+1]*gamma\n",
    "    return discounted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action(action_distribution, epsilon=1e-1):\n",
    "    if random.random() < epsilon:\n",
    "        return np.argmax(np.random.random(\n",
    "           action_distribution.shape))\n",
    "    else:\n",
    "        return np.argmax(action_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_action_annealed(action_distribution,\n",
    "                                   episode,\n",
    "                                   episode_stop,\n",
    "                                   epsilon_start=1.0, \n",
    "                                   epsilon_end=1e-2):\n",
    "    if (episode<episode_stop):\n",
    "        annealed_epsilon = epsilon_start*(1.0-(episode/episode_stop)) + epsilon_end*(episode/episode_stop)\n",
    "    else:\n",
    "        annealed_epsilon = epsilon_end\n",
    "    if random.random() < annealed_epsilon:\n",
    "        return np.argmax(np.random.random(action_distribution.shape))\n",
    "    else:\n",
    "        return np.argmax(action_distribution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2][False] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is about single episodes\n",
    "class EpisodeHistory(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.state_primes = []\n",
    "        self.discounted_returns = []\n",
    "\n",
    "    def add_to_history(self, state, action, reward, \n",
    "      state_prime):\n",
    "        self.states.append(state)\n",
    "        self.actions.append(action)\n",
    "        self.rewards.append(reward)\n",
    "        self.state_primes.append(state_prime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this holds multiple episodes\n",
    "class Memory(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.state_primes = []\n",
    "        self.discounted_returns = []\n",
    "\n",
    "    def reset_memory(self):\n",
    "        self.states = []\n",
    "        self.actions = []\n",
    "        self.rewards = []\n",
    "        self.state_primes = []\n",
    "        self.discounted_returns = []\n",
    "\n",
    "    def add_episode(self, episode):\n",
    "        self.states += episode.states\n",
    "        self.actions += episode.actions\n",
    "        self.rewards += episode.rewards\n",
    "        self.discounted_returns += episode.discounted_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PGAgent(object):\n",
    "\n",
    "    def __init__(self, session, state_size, num_actions,\n",
    "        hidden_size, learning_rate=1e-3):\n",
    "        self.session = session\n",
    "        self.state_size = state_size\n",
    "        self.num_actions = num_actions\n",
    "        self.hidden_size = hidden_size\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        self.build_model()\n",
    "        self.build_training()\n",
    "\n",
    "    def build_model(self):\n",
    "        with tf.variable_scope('pg-model'):\n",
    "            self.state = tf.placeholder(\n",
    "                shape=[None, self.state_size], \n",
    "                dtype=tf.float32)\n",
    "            self.h0 = slim.fully_connected(self.state, \n",
    "            self.hidden_size)\n",
    "            self.h1 = slim.fully_connected(self.h0, \n",
    "            self.hidden_size)\n",
    "#             self.output = slim.fully_connected(\n",
    "#                 self.h1, self.num_actions, \n",
    "#                 activation_fn=tf.nn.softmax)\n",
    "#             # more hidden layers\n",
    "            self.h2 = slim.fully_connected(self.h1, \n",
    "            self.hidden_size)\n",
    "            self.h3 = slim.fully_connected(self.h2, \n",
    "            self.hidden_size)\n",
    "            self.h4 = slim.fully_connected(self.h3, \n",
    "            self.hidden_size)\n",
    "            self.output = slim.fully_connected(\n",
    "                self.h4, self.num_actions, \n",
    "                activation_fn=tf.nn.softmax)\n",
    "\n",
    "    def build_training(self):\n",
    "        self.action_input = tf.placeholder(tf.int32, \n",
    "          shape=[None])\n",
    "        self.reward_input = tf.placeholder(tf.float32, \n",
    "          shape=[None])\n",
    "\n",
    "        # Select the logits related to the action taken\n",
    "# this creates list of indices ?(ie num samples) long that are at start of each row in one-hot - then \n",
    "# adds indexes into each row of\n",
    "# particular pre-selected action\n",
    "        self.output_index_for_actions = (tf.range(\n",
    "            0, tf.shape(self.output)[0]) * \n",
    "              tf.shape(self.output)[1]) + self.action_input\n",
    "# then this flattens everything into 1-D, then selects from it using those indices\n",
    "# all of this is a way to select only the neuron outputs that correspond to just the actions taken, rather\n",
    "# than getting the values for all actions\n",
    "        self.logits_for_actions = tf.gather(\n",
    "            tf.reshape(self.output, [-1]), \n",
    "            self.output_index_for_actions)\n",
    "\n",
    "        self.loss = -tf.reduce_mean(tf.log(tf.clip_by_value(self.logits_for_actions,1e-10,1.0)) * \n",
    "              self.reward_input)\n",
    "# see book pg. 254\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate=self.learning_rate)\n",
    "        self.train_step = self.optimizer.minimize(self.loss)\n",
    "\n",
    "    def predict_action(self, \n",
    "                       state,\n",
    "                       episode,\n",
    "                       episode_stop,\n",
    "                       epsilon_start=1.0,\n",
    "                       epsilon_end=1e-2\n",
    "        ):\n",
    "        action_distribution = self.session.run(\n",
    "            self.output, \n",
    "            feed_dict={self.state: [state]}\n",
    "        )#[0]\n",
    "#       print('action dist',action_distribution)\n",
    "        action = epsilon_greedy_action_annealed(action_distribution,\n",
    "                                                episode,\n",
    "                                                episode_stop\n",
    "        )\n",
    "        return action\n",
    "    \n",
    "    def predict_action_0ep(self, \n",
    "                       state\n",
    "        ):\n",
    "        return np.argmax(self.session.run(\n",
    "            self.output, \n",
    "            feed_dict={self.state: [state]}\n",
    "        ))\n",
    "    \n",
    "    def show_current_policy(self):\n",
    "        # Evaluate Current Policy - No Epsilon ------------------------------------\n",
    "        pol_ep_hist = EpisodeHistory()\n",
    "        state = env.reset()\n",
    "        for n in range(20):    # figure out next action\n",
    "            action = agent.predict_action_0ep(state)\n",
    "            # take a step\n",
    "            state_prime, reward, terminal, _ = env.step(action)\n",
    "            state = state_prime\n",
    "            pol_ep_hist.add_to_history(state, action, reward, state_prime)\n",
    "        print('Policy Actions - No Epsilon')\n",
    "        print(pol_ep_hist.actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johnnybravo/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "  1%|          | 11/2000 [00:00<00:40, 49.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "global memory:  [6, 8, 6, 5, 0, 2, 6, 8, 3, 5, 5, 1, 6, 5, 4, 1, 6, 6, 4, 7, 4, 5, 3, 6, 2, 8, 2, 2, 5, 8, 7, 7, 7, 0, 3, 2, 2, 1, 1, 0, 2, 1, 2, 0, 5, 4, 2, 6, 6, 2, 4, 2, 1, 2, 4, 1, 7]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "global memory:  [0, 2, 3, 3, 7, 1, 8, 5, 5, 2, 6, 6, 6, 6, 0, 7, 6, 3, 2, 3, 3, 7, 6, 5, 6, 1, 8, 4, 6, 6, 4, 8, 0, 7, 8, 0, 2, 6, 3, 3, 1, 4, 8, 7, 4, 5, 0, 0, 8, 4, 0, 8, 6, 3, 0, 2, 2, 5, 0, 0, 1, 2, 2, 5, 7, 0, 4, 0, 3, 6, 2, 1, 0, 4, 1, 1, 7, 5, 7, 7, 2, 4, 6, 5, 3, 0, 5, 6, 5, 4, 6, 8, 8, 4, 4, 2, 8, 7, 8, 0, 3, 7, 5, 0, 2, 3, 1, 0, 8, 1, 4, 0, 1, 0, 3, 2, 4, 0, 0, 7, 8, 5, 6, 3, 5, 5, 4, 8, 0, 4, 7, 2, 2, 4, 3, 7, 8, 4, 8, 8, 6, 3, 5, 2, 2, 1, 7, 6, 2, 1, 6, 7, 1, 7, 2, 2, 6, 8, 6, 2, 3, 0, 3, 8, 8, 5, 0, 2, 7, 1, 6, 2, 0, 7, 0, 7, 4, 4, 0, 8, 1, 4, 6, 7, 3, 7, 6, 6, 6, 6, 1, 6, 1, 5, 3, 6, 7, 7, 4, 7, 6, 3, 0, 1, 5, 1, 0, 6, 8, 3, 4, 7, 4, 8, 2, 8, 0, 5, 3, 7, 2, 2, 8, 1, 6, 2, 0, 0, 6, 6, 6, 7, 1, 6, 7, 0, 5, 8, 2, 3, 4, 7, 5, 0, 2, 1, 0, 0, 1, 4, 4, 1, 6, 7, 8, 8, 5, 1, 1, 1, 4, 4, 0, 5, 3, 6, 5, 8, 4, 2, 7, 4, 1, 2, 7, 0, 8, 2, 7, 6, 2, 5, 6, 0, 4, 6, 5, 1, 6, 4, 1, 1, 5, 7, 8, 7, 4, 7, 5, 3, 8, 7, 1, 1, 1, 1, 2, 0, 8, 8, 6, 8, 3, 3, 0, 5, 6, 0, 5, 5, 3, 7, 8, 6, 5, 6, 6, 4, 0, 7, 6, 4, 1, 0, 1, 5, 8, 6, 2, 0, 6, 8, 7, 2, 4, 4, 8, 8, 1, 8, 0, 8, 5, 6, 2, 1, 3, 0, 0, 0, 2, 4, 1, 2, 4, 6, 4, 7, 2, 8, 7, 5, 6, 8, 0, 4, 3, 7, 0, 5, 1, 3, 7, 7, 4, 1, 5, 2, 2, 2, 7, 4, 4, 3, 8, 3, 7, 3, 2, 7, 7, 0, 1, 6, 7, 6, 5, 3, 1, 5, 6, 7, 7, 2, 6, 8, 6, 3, 1, 0, 5, 1, 3, 7, 5, 0]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 28/2000 [00:00<00:31, 62.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "global memory:  [6, 1, 3, 5, 1, 3, 3, 5, 7, 4, 3, 2, 2, 3, 0, 7, 6, 2, 8, 3, 5, 3, 7, 0, 4, 7, 1, 4, 5, 8, 7, 2, 7, 6, 6, 3, 2, 2, 0, 5, 8, 2, 5, 6, 2, 3, 0, 7, 1, 2, 1, 7, 0, 4, 4, 1, 4, 4, 1, 6, 4, 6, 3, 5, 7, 2, 1, 3, 0, 6, 4, 4, 0, 7, 4, 8, 3, 4, 1, 2, 5, 7, 6, 3, 7, 1, 3, 2, 8, 8, 1, 0, 4, 7, 7, 1, 8, 1, 6, 7, 5, 6, 8, 0, 5, 7, 1, 3, 3, 5, 6, 1, 6, 1, 6, 8, 3, 4, 8, 0, 6, 2, 5, 3, 3, 1, 0, 1, 3, 0, 4, 4, 7, 1, 2, 4, 7, 2, 2, 3, 6, 0, 5, 4, 4, 8, 7, 3, 6, 2, 5, 2, 2, 1, 4, 3, 8, 2, 5, 2, 8, 5, 7, 1, 6, 3, 2, 7, 1, 3, 0, 1, 8, 7, 4, 2, 4, 8, 4, 6, 0, 7, 0, 1, 6, 7, 1, 2, 4, 8, 2, 3, 4, 4, 5, 7, 5, 6, 8, 7, 3, 3, 2, 4, 8, 3, 6, 1, 2, 5, 6, 2, 6, 6, 0, 2, 6, 1, 7, 2, 8, 5, 7, 5, 5, 4, 5, 2, 2, 6, 3, 0, 1, 6, 7, 2, 3, 3, 8, 3, 1, 3, 5, 1, 1, 5, 6, 2, 2, 6, 4, 8, 6, 8, 5, 8, 3, 5, 3, 2, 0, 7, 8, 5, 6, 8, 3, 2, 1, 6, 0, 8, 6, 1, 0, 2, 4, 2, 4, 8, 4, 2, 4, 8]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "global memory:  [6, 3, 7, 4, 4, 5, 7, 4, 0, 7, 5, 5, 7, 7, 6, 6, 1, 1, 1, 1, 4, 8, 1, 2, 7, 1, 3, 4, 4, 2, 5, 8, 5, 1, 8, 6, 5, 6, 4, 5, 6, 1, 5, 3, 2, 8, 2, 0, 6, 8, 6, 0, 7, 7, 0, 2, 1, 6, 3, 1, 2, 3, 1, 5, 5, 8, 7, 6, 6, 5, 8, 0, 3, 6, 7, 0, 2, 2, 4, 8, 6, 5, 2, 0, 7, 3, 1, 2, 8, 2, 1, 3, 6, 4, 5, 5, 7, 7, 1, 0, 1, 2, 1, 8, 1, 5, 5, 2, 3, 3, 0, 6, 0, 5, 2, 8, 0, 2, 2, 4, 0, 5, 7, 6, 5, 6, 0, 1, 7, 0, 3, 4, 6, 4, 5, 7, 0, 4, 2, 4, 5, 6, 5, 0, 5, 6, 4, 8, 7, 8, 8, 5, 6, 2, 7, 7, 3, 6, 4, 3, 7, 5, 1, 6, 0, 7, 8, 2, 2, 7, 2, 6, 7, 8, 0, 1, 5, 5, 8, 8, 3, 3, 6, 3, 5, 6, 0, 8, 2, 5, 8, 3, 8, 2, 6, 1, 8, 2, 4, 8, 1, 1, 3, 7, 7, 8, 0, 0, 5, 5, 5, 7, 4, 1, 5, 3, 6, 7, 5, 0, 0, 2, 4, 8, 7, 1, 8, 8, 6, 7, 8, 5, 6, 1, 3, 5, 0, 1, 8, 6, 0, 7, 5, 6, 1, 3, 6, 1, 1, 1, 3, 3, 1, 6, 4, 3, 8, 0, 2, 0, 6, 5, 5, 3, 0, 3, 3, 3, 2, 0, 2, 0, 5, 7, 2, 2, 6, 0, 5, 0, 0, 0, 8, 8, 1, 1, 5, 8, 1, 4, 3, 5, 1, 7, 7, 1, 1, 6, 0, 2, 7, 8, 5, 2, 0, 8, 6, 3, 8, 3, 8, 7, 6, 5, 7, 1, 4, 2, 4, 1, 3, 3, 4, 6, 8, 3, 5, 4, 5, 3, 3, 7, 2, 3, 5, 4, 5, 6, 3, 4, 3, 7, 1, 7, 2, 1, 0, 6, 6, 6, 6, 0, 0, 5, 7, 3, 5, 1, 5, 2, 5, 3, 2, 6, 3, 3, 1, 6, 5, 2, 4, 2, 2, 5, 0, 3, 1, 7, 5, 6, 3, 3, 5, 3]\n",
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 58/2000 [00:00<00:25, 75.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "global memory:  [5, 4, 1, 1, 2, 4, 8, 2, 4, 6, 3, 5, 7, 6, 2, 3, 8, 8, 5, 2, 6, 1, 7, 4, 5, 1, 7, 8, 0, 4, 4, 0, 8, 8, 8, 7, 8, 4, 8, 4, 4, 2, 6, 2, 5, 5, 1, 5, 4, 5, 1, 0, 1, 6, 7, 4, 0, 5, 2, 6, 8, 1, 1, 3, 3, 7, 4, 6, 3, 7, 2, 2, 8, 1, 5, 6, 0, 4, 3, 2, 5, 3, 6, 3, 7, 5, 5, 7, 7, 7, 5, 4, 5, 6, 4, 7, 7, 5, 5, 8, 0, 4, 3, 3, 2, 8, 0, 7, 3, 1, 3, 0, 8, 6, 0, 4, 4, 8, 5, 7, 6, 1, 7, 2, 3, 4, 7, 4, 5, 4, 1, 3, 3, 2, 4, 1, 5, 3, 8, 6, 2, 8, 6, 5, 0, 4, 4, 5, 3, 3, 2, 5, 1, 0, 1, 6, 8, 0, 2, 6, 5, 5, 6, 4, 8, 6, 7, 3, 6, 4, 5, 7, 7, 7, 4, 7, 8, 4, 0, 4, 5, 5, 6, 4, 2, 4, 8]\n",
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "global memory:  [3, 5, 5, 1, 3, 2, 0, 4, 7, 4, 1, 3, 3, 7, 5, 2, 5, 6, 3, 5, 1, 4, 8, 3, 5, 2, 5, 6, 3, 5, 0, 1, 6, 5, 5, 1, 0, 5, 8, 0, 2, 0, 5, 2, 4, 3, 4, 8, 4, 3, 3, 0, 5, 3, 2, 6, 8, 0, 3, 5, 5, 5, 0, 3, 5, 1, 7, 4, 5, 6, 1, 6, 0, 5, 8, 2, 6, 4, 4, 2, 3, 2, 4, 1, 7, 1, 4, 8, 3, 8, 7, 0, 3, 5, 4, 6, 2, 7, 1, 7, 7, 1, 3, 4, 7, 5, 3, 1, 1, 8, 6, 7, 3, 4, 0, 7, 6, 0, 6, 5, 5, 4, 4, 5, 5, 1, 6, 0, 1, 3, 4, 6, 8, 0, 4, 2, 5, 6, 1, 6, 3, 0, 6, 1, 5, 4, 3, 5, 6, 5, 7, 7, 5, 5, 7, 7, 8, 1, 7, 2, 6, 8, 7, 2, 8, 6, 2, 5, 2, 2, 5, 2, 0, 7, 5, 5, 8, 1, 3, 3, 8, 3, 5, 4, 5, 5, 6, 0, 0, 5, 8, 0, 4, 8, 4, 2, 5, 1, 5, 8, 5, 1, 5, 1, 1, 8, 2, 6, 7, 3, 2, 1, 4, 8, 8, 4, 7, 1, 1, 1]\n",
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 74/2000 [00:00<00:25, 75.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "global memory:  [1, 3, 2, 5, 6, 8, 3, 3, 3, 8, 2, 0, 8, 4, 3, 6, 7, 5, 2, 7, 6, 4, 5, 2, 5, 3, 6, 8, 1, 5, 2, 7, 7, 6, 1, 4, 4, 3, 8, 8, 7, 5, 1, 0, 5, 8, 7, 5, 5, 4, 4, 5, 0, 4, 2, 4, 6, 4, 3, 3, 6, 2, 1, 5, 6, 6, 2, 5, 1, 3, 5, 7, 6, 1, 7, 5, 6, 3, 8, 5, 8, 5, 8, 5, 1, 2, 2, 6, 6, 6, 8, 6, 8, 8, 5, 4, 6, 1, 6, 0, 0, 7, 4, 6, 1, 7, 5, 6, 4, 8, 3, 5, 2, 7, 3, 5, 5, 0, 1, 8, 6, 4, 6, 2, 6, 4, 7, 8, 4, 2, 8, 0, 6, 7, 2, 8, 0, 4, 8, 8, 7, 0, 1, 7, 7, 6, 8, 1, 5, 3, 0, 3, 2, 6, 0, 3, 5, 7, 7, 0, 4, 5, 0, 5, 0, 2, 6, 3, 0, 0, 6, 4, 4, 2, 2, 3, 7, 0, 3, 5, 4, 8, 6, 2, 0, 2, 0, 3, 1, 1, 8, 3, 6, 7, 5, 0, 8, 3, 0, 0, 3, 6, 6, 1, 3, 8, 1, 4, 7, 4, 1, 6, 3, 7, 6, 4, 4, 8, 8, 8, 0, 3, 5, 5, 3, 8, 0, 2, 5, 1, 5, 2, 2, 2, 3, 0, 3, 7, 7, 5, 1, 0, 8, 5, 5, 1, 3, 2, 8, 0, 5, 3, 1, 0, 3, 0, 8, 5, 1, 1, 5, 8, 7, 8, 6, 1, 0, 5, 2, 6, 0, 0, 3, 5, 6, 6, 1, 6, 7, 6, 5, 1, 1, 5, 0, 3, 5, 8, 5, 1, 0, 2, 7, 5, 3, 8, 3, 8, 1, 7, 6, 3, 5, 8, 3, 7, 5, 1, 8, 5, 4, 6, 8, 5, 8, 8, 5, 6, 0, 7, 7, 8, 7, 1, 5, 5, 7, 7, 3, 0, 7, 5, 3, 3, 0, 6, 5, 8, 5, 8, 6, 0, 4, 6, 5, 3, 3, 5, 4, 7, 2, 8, 8, 4, 8, 7, 6, 7, 1, 8, 2, 2, 5, 4, 5, 1, 2, 8, 6, 5, 7, 4, 2, 0, 1, 7, 5, 4, 3]\n",
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "global memory:  [4, 3, 6, 4, 4, 1, 8, 8, 1, 7, 4, 5, 4, 4, 0, 4, 5, 6, 6, 1, 2, 0, 7, 0, 5, 3, 0, 4, 2, 5, 3, 4, 7, 8, 8, 0, 4, 3, 5, 0, 2, 7, 4, 6, 8, 1, 8, 8, 2, 4, 7, 2, 3, 1, 3, 6, 4, 0, 7, 5, 8, 2, 0, 8, 4, 2, 0, 0, 4, 2, 2, 7, 0, 4, 3, 2, 0, 0, 8, 1, 3, 7, 1, 2, 0, 4, 5, 1, 7, 6, 5, 4, 4, 2, 7, 1, 6, 6, 6, 8, 8, 8, 3, 7, 5, 5, 4, 8, 5, 7, 8, 5, 7, 7, 0, 2, 3, 5, 3, 6, 3, 7, 5, 4, 2, 0, 5, 4, 8, 1, 0, 8, 1, 6, 8, 0, 7, 5, 0, 0, 7, 8, 2, 3, 8, 6, 6, 2, 8, 1, 2, 2, 0, 2, 5, 4, 2, 4, 6, 1, 1, 5, 5, 5, 3, 2, 0, 0, 0, 1, 7, 0, 1, 5, 0, 0, 8, 5, 7, 3, 0, 8, 4, 5, 7, 0, 2, 0, 7, 5, 0, 3, 7, 6, 6, 2, 5, 4, 4, 0, 2, 2, 3, 0, 0, 8, 1, 5, 6, 4, 4, 5, 6, 4, 8, 5, 7, 0, 1, 4, 4, 6, 3, 0, 4, 5, 0, 1, 4, 3, 0, 6, 6, 3, 4, 1, 2, 1, 1, 5, 8, 7, 4, 3, 0, 0, 1, 1, 7, 0, 7, 2, 7, 3, 7, 5, 4, 3, 2, 0, 2, 2, 5, 7, 5, 4, 2]\n",
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 91/2000 [00:01<00:25, 73.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5]\n",
      "global memory:  [3, 2, 0, 8, 1, 0, 7, 7, 5, 1, 1, 3, 1, 2, 7, 7, 5, 6, 6, 8, 1, 8, 6, 1, 7, 4, 6, 4, 4, 3, 8, 3, 8, 0, 5, 4, 2, 5, 1, 4, 5, 2, 3, 5, 0, 3, 5, 0, 7, 5, 1, 7, 3, 8, 0, 3, 0, 8, 7, 7, 6, 5, 5, 3, 8, 3, 1, 0, 0, 4, 8, 0, 7, 4, 2, 0, 0, 5, 7, 1, 5, 6, 0, 4, 5, 8, 2, 1, 7, 1, 5, 4, 0, 2, 2, 4, 5, 5, 1, 1, 5, 8, 8, 5, 5, 3, 4, 4, 8, 2, 3, 8, 0, 1, 4, 4, 4, 0, 1, 8, 6, 1, 2, 6, 7, 0, 4, 8, 7, 4, 6, 6, 4, 6, 6, 5, 7, 0, 8, 2, 4, 7, 0, 0, 2, 1, 8, 6, 6, 8, 7, 6, 5, 1, 5, 5, 4, 5, 8, 2, 5, 8, 5, 3, 4, 2, 3, 1, 8, 4, 5, 6, 3, 5, 0, 4, 2, 4, 8, 8, 6, 2, 1, 4, 6, 7, 2, 3, 5, 2, 5, 3, 5, 5, 5, 8, 5, 4, 2, 5, 8, 7, 3, 5, 7, 7, 5, 0, 2, 2, 7, 5, 2, 8, 5, 1, 6, 7, 7, 2, 1, 2, 8, 5, 2, 2, 1, 5, 4, 3, 5, 2, 0, 6, 5, 4, 3, 1, 5, 7, 7, 1, 0, 3, 7, 7, 3]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5, 8, 5]\n",
      "global memory:  [3, 6, 5, 3, 0, 7, 7, 2, 6, 8, 6, 3, 8, 0, 1, 1, 6, 5, 1, 1, 4, 4, 2, 0, 4, 5, 8, 7, 1, 3, 2, 8, 4, 5, 7, 2, 3, 0, 6, 5, 0, 7, 4, 3, 0, 8, 4, 4, 4, 8, 5, 4, 8, 1, 0, 3, 2, 5, 8, 8, 0, 0, 1, 1, 5, 2, 7, 8, 4, 5, 6, 8, 8, 3, 8, 3, 3, 1, 6, 1, 0, 0, 8, 4, 5, 8, 3, 5, 3, 3, 1, 2, 5, 6, 0, 8, 1, 2, 3, 1, 8, 0, 5, 0, 8, 2, 1, 8, 3, 6, 2, 5, 4, 4, 0, 7, 6, 5, 0, 1, 5, 8, 2, 3, 8, 7, 5, 4, 8, 1, 6, 2, 8, 3, 8, 7, 6, 6, 4, 8, 7, 1, 0, 3, 4, 5, 7, 5, 7, 4, 7, 3, 6, 5, 8, 6, 2, 3, 5, 4, 5, 8, 5, 8, 2, 0, 8, 6, 0, 2, 5, 0, 4, 7, 8, 2, 8, 5, 6, 6, 5, 8, 0, 6, 5, 0, 7, 1, 5, 4, 7, 1, 7, 0, 6, 1, 0, 6, 5, 5, 6, 5, 5, 3, 7, 1, 4, 6, 5, 5, 8, 4, 7, 7, 2, 5, 5, 0, 6, 7, 5, 7, 4, 6, 2, 3, 8, 0, 3, 3, 7, 1, 1, 8, 8, 5, 6, 5, 8, 5, 6, 8, 6, 1, 5, 8, 0, 6, 7, 5, 4, 2, 6, 4, 8, 2, 2, 5, 5, 5, 1, 1, 5, 6, 5, 3, 6, 3, 8, 8, 3, 3, 4, 0, 5, 8, 6, 5, 8, 0, 4, 5, 0, 3, 3, 4, 4, 4, 7, 6, 7, 2, 7, 6, 5, 0, 8, 3, 0, 5, 4, 6, 7, 6, 6, 6, 5, 8, 1, 5, 5, 2, 5, 5, 5, 4, 7, 6, 2, 2, 3, 1, 0, 8, 4, 7, 2, 2, 5, 3, 0, 2, 0, 5, 2, 7, 6, 4, 5, 8, 2, 3, 7, 4, 8, 3, 3, 0]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 5, 8, 5, 8, 5, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 106/2000 [00:01<00:26, 71.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 5, 8, 5, 8, 5, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "global memory:  [7, 2, 2, 3, 8, 7, 1, 7, 0, 6, 5, 5, 2, 0, 0, 7, 7, 5, 1, 2, 1, 6, 2, 1, 8, 2, 5, 5, 0, 7, 5, 5, 2, 8, 6, 0, 2, 5, 6, 0, 5, 1, 5, 8, 8, 2, 8, 1, 5, 2, 7, 1, 3, 8, 6, 6, 2, 4, 2, 4, 7, 8, 3, 6, 6, 1, 4, 2, 7, 4, 2, 0, 3, 2, 3, 8, 7, 5, 8, 4, 3, 4, 1, 3, 2, 4, 7, 2, 3, 5, 1, 8, 0, 8, 7, 2, 5, 8, 2, 8, 0, 8, 1, 4, 8, 5, 2, 1, 7, 7, 7, 5, 0, 5, 4, 6, 5, 3, 8, 8, 3, 7, 2, 5, 7, 6, 8, 0, 8, 2, 7, 1, 8, 5, 1, 1, 6, 6, 8, 6, 5, 2, 8, 5, 3, 2, 3, 2, 0, 7, 7, 3, 1, 7, 3, 0, 8, 7, 2, 7, 7, 2, 2, 4, 8, 2, 4, 0, 6, 3, 7, 3, 4, 2, 0, 7, 4, 2, 0, 0, 8, 8, 5, 5, 8, 1, 0, 8, 3, 7, 5, 4, 6, 1, 1, 6, 4, 8, 1, 8, 0, 5, 2, 4, 8, 5, 8, 1, 7, 5, 8, 2, 5, 8, 6, 2, 6, 6, 5, 4, 1, 3, 6, 2, 4, 5, 8, 8, 8, 2, 2, 7, 4, 7, 7, 2, 3, 5, 6, 4, 6, 3, 0, 5, 1, 2, 8, 0, 1, 1, 8, 0, 5, 8, 1, 2, 0, 7, 4, 8, 7, 6, 2, 6, 2, 5, 1, 5, 6, 5, 8, 5, 4, 0, 7, 8, 2, 3, 3, 1, 5, 5, 8, 8, 5, 1, 7, 6, 4, 2, 1, 2, 7, 2, 6, 2, 7, 3, 6, 8, 0, 5, 5, 1, 3, 8, 6, 8, 4, 8, 6, 2, 1, 7, 3, 5, 1, 0, 3, 1, 4, 4, 1, 8, 0, 7, 2, 1, 1, 8, 5, 0, 0, 8, 6, 8, 6, 3, 5, 4, 0, 4, 4, 2, 8, 0, 6, 5, 3, 6, 2, 4, 1, 8, 2, 2, 6, 4, 8, 4, 8, 8, 8, 5, 5, 1, 4, 8, 4, 1, 3, 3, 7, 6, 5, 1, 3, 6, 8, 4, 0, 4, 8, 0, 2, 1, 7, 5, 5, 4, 4, 8, 3, 1, 7, 4, 4, 6, 8, 7, 7, 2, 2, 3, 5, 2, 4, 8, 7, 5, 5, 3, 3, 4, 2, 8, 3, 8, 8, 1, 4, 8, 2, 4, 2]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 8, 2, 2, 2, 8, 2, 2, 2, 8]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 8, 2, 2, 2, 8, 2, 2, 2, 8]\n",
      "global memory:  [7, 8, 5, 1, 2, 6, 6, 1, 5, 0, 6, 1, 0, 6, 2, 1, 8, 2, 2, 1, 2, 3, 8, 8, 8, 4, 3, 0, 8, 6, 6, 3, 8, 0, 5, 3, 3, 3, 8, 8, 6, 2, 7, 4, 6, 4, 6, 4, 7, 5, 2, 1, 6, 4, 5, 7, 0, 6, 5, 2, 1, 6, 7, 6, 4, 6, 1, 1, 8, 0, 3, 2, 8, 0, 2, 2, 4, 1, 0, 7, 2, 6, 4, 2, 6, 6, 5, 2, 2, 4, 0, 4, 8, 8, 8, 8, 1, 0, 7, 0, 7, 5, 2, 6, 5, 0, 2, 6, 4, 2, 2, 8, 8, 7, 8, 3, 1, 6, 8, 3, 0, 7, 8, 1, 7, 5, 3, 7, 8, 8, 8, 1, 0, 8, 6, 2, 6, 6, 8, 1, 2, 5, 2, 1, 6, 1, 1, 6, 6, 5, 7, 7, 4, 4, 7, 6, 2, 6, 0, 6, 1, 6, 5, 4, 1, 5, 8, 5, 5, 0, 4, 3, 5, 7, 8, 3, 3, 2, 2, 7, 2, 3, 3, 5, 6, 8, 4, 8, 2, 5, 3, 1, 1, 8, 7, 4, 0, 3, 5, 0, 2, 6, 5, 5, 6, 7, 0, 5, 5, 6, 0, 4, 4, 1, 3, 4, 2, 6, 1, 6, 8, 1, 4, 3, 8, 2, 8, 6, 2, 0, 2, 8, 5, 7, 3, 7, 8, 6, 0, 5, 0, 2, 3, 4, 7, 5, 7, 6, 3, 6, 5, 6, 5, 2, 8, 8, 4, 3, 6, 8, 0, 4, 8, 7, 1, 0, 6, 7, 4, 1, 0, 8, 6, 5, 2, 3, 2, 3, 8, 6, 8, 7, 3, 0, 2, 8, 8, 6, 5, 1, 1, 4, 8, 1, 7, 5, 3, 4, 1, 2, 3, 3, 4, 3, 4, 8, 4, 8, 3, 8, 2, 8, 2, 1, 8, 7, 8, 7, 2, 1, 1, 8, 5, 8, 5, 4, 7, 4, 7, 8, 7, 7, 3, 5, 0, 5, 1, 2, 7, 6, 0, 8, 6, 1, 1, 8, 1, 8, 2, 4, 7, 1, 3, 7, 4, 8, 5, 6, 4, 4, 6, 2, 0, 8, 6, 8, 0, 0, 6, 5, 8, 6, 7, 1, 3, 8, 2, 5, 6, 8, 5, 3, 7, 5, 0, 0, 5, 8, 4, 6, 8, 5, 6, 0, 6, 1, 0, 3, 8, 2, 3, 7, 1, 3, 7, 8, 4, 6, 5, 8, 7, 2, 5, 5, 0, 4, 1, 1, 1, 0, 6, 8, 5, 6, 6, 0, 4, 1, 5, 0, 6, 0, 3, 6, 5, 8, 1, 2, 2, 0, 7, 5, 4, 1, 7, 4, 7, 0, 5, 0, 8, 6, 5, 7, 8, 0, 1, 0, 7, 3, 4, 3, 6, 6, 0, 3, 8, 6, 6, 5, 8, 7, 1, 2, 8, 7, 1, 1, 7, 4, 5, 0, 3, 4, 3, 2, 4, 4, 5, 3, 5, 1, 5, 8]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 8, 2, 2, 2, 8, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 131/2000 [00:01<00:26, 70.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 2, 2, 8, 2, 2, 2, 8, 2]\n",
      "global memory:  [3, 4, 2, 8, 6, 7, 3, 8, 6, 0, 4, 5, 7, 4, 7, 3, 7, 0, 3, 4, 6, 4, 5, 3, 8, 4, 5, 2, 6, 7, 4, 7, 3, 8, 6, 5, 8, 2, 4, 0, 3, 8, 8, 8, 4, 1, 5, 5, 6, 3, 1, 3, 7, 8, 3, 1, 0, 3, 1, 2, 5, 3, 4, 7, 7, 5, 0, 1, 1, 3, 8, 1, 5, 8, 7, 2, 2, 8, 4, 4, 7, 3, 5, 2, 0, 2, 0, 6, 4, 3, 5, 0, 4, 8, 5, 8, 5, 8, 6, 0, 7, 8, 4, 7, 6, 2, 1, 5, 8, 4, 7, 1, 4, 0, 4, 5, 6, 4, 4, 7, 7, 3, 1, 5, 3, 4, 8, 6, 3, 0, 6, 3, 8, 8, 8, 0, 8, 4, 4, 8, 5, 1, 7, 0, 5, 0, 1, 8, 6, 1, 4, 6, 4, 6, 5, 2, 2, 0, 8, 1, 7, 1, 8, 6, 1, 5, 5, 4, 6, 5, 8, 4, 1, 2, 5, 1, 6, 7, 1, 8, 8, 1, 1, 8, 3, 0, 6, 7, 8, 7, 7, 1, 8, 0, 0, 8, 8, 8, 3, 2, 2, 8, 5, 8, 2, 7, 6, 8, 1, 0, 8, 1, 8, 2, 6, 5, 8, 5, 0, 8, 7, 2, 2, 7, 2, 4, 7, 2, 4, 5, 3, 7, 5, 1, 5, 8, 7, 1, 8, 6, 2, 6, 2, 1, 2, 7, 5, 8, 8, 2, 0, 8, 8, 1, 8, 7, 4, 3, 8, 8, 8, 8, 6, 8, 7, 0, 3, 1, 1, 5, 4, 4, 6, 5, 3, 7, 0, 8, 0, 5, 4, 4, 8]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8, 2, 2, 2, 8, 2, 2]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8, 2, 2, 2, 8, 2, 2]\n",
      "global memory:  [5, 1, 8, 3, 8, 3, 1, 2, 4, 8, 8, 7, 1, 0, 5, 1, 2, 8, 6, 1, 1, 2, 4, 2, 8, 8, 0, 6, 1, 8, 5, 3, 1, 8, 6, 3, 0, 3, 5, 8, 4, 1, 0, 7, 6, 8, 8, 4, 4, 4, 1, 2, 2, 8, 2, 6, 6, 6, 2, 8, 5, 2, 1, 2, 8, 1, 3, 0, 2, 8, 0, 6, 8, 7, 8, 8, 0, 4, 7, 8, 5, 8, 1, 6, 6, 4, 2, 2, 6, 8, 3, 8, 8, 0, 2, 7, 3, 4, 1, 7, 8, 3, 1, 1, 0, 3, 6, 5, 3, 6, 6, 8, 6, 0, 7, 2, 6, 7, 6, 1, 4, 3, 5, 4, 0, 3, 5, 4, 2, 3, 8, 1, 0, 3, 7, 6, 7, 1, 1, 8, 8, 2, 2, 1, 1, 4, 0, 8, 3, 6, 4, 5, 5, 1, 3, 1, 2, 5, 7, 1, 8, 6, 0, 1, 6, 5, 3, 2, 6, 8, 1, 3, 0, 1, 7, 1, 2, 3, 8, 7, 7, 5, 2, 2, 5, 8, 2, 0, 4, 8, 3, 2, 8, 6, 1, 1, 8, 5, 2, 8, 6, 5, 6, 7, 8, 4, 3, 3, 3, 0, 8, 2, 5, 8, 5, 3, 2, 4, 0, 8, 3, 2, 3, 7, 5, 8, 1, 4, 4, 8, 3, 8, 3, 5, 5, 8, 2, 8, 6, 8, 3, 8, 7, 1, 3, 4, 8, 2, 8, 3, 1, 7, 8, 1, 5, 0, 8, 6, 8, 8, 6, 6, 6, 4, 2, 1, 3, 2, 0, 2, 1, 7, 5, 3, 5, 0, 1, 0, 8, 1, 0, 0, 8, 7, 5, 8, 7, 0, 0, 5, 5, 8, 1, 8, 8, 6, 8, 5, 0, 7, 7, 0, 8, 0, 4, 0, 8, 0, 3, 6, 8, 5, 5, 6, 4, 5, 1, 8, 6, 7, 6, 2, 4, 8, 3, 3, 8, 5, 8, 5, 4, 4, 8, 2, 8, 8, 6, 4, 4, 6, 3, 1, 4, 0, 4, 4, 6, 8, 0, 0, 1, 5, 2, 8, 0, 8, 6, 5, 7, 7, 8, 3, 4, 2, 8, 5, 8, 0, 6, 0, 1, 4, 3, 2, 8, 5, 4, 3, 8, 5, 0, 8, 0, 6, 0, 8, 8, 8, 5, 8, 1, 6, 0, 5, 8, 8, 1, 8, 1, 6, 4, 1, 2, 8, 4, 1, 0, 1, 6, 2, 3, 8, 7, 3, 1, 1, 8, 5, 6, 2, 0, 1, 6, 8, 8, 8, 2, 7, 7, 2, 4, 5, 6, 3, 2, 2, 6, 7, 1, 3, 0, 1, 6, 7, 6, 7, 3, 5, 1, 7, 1, 2, 6, 4, 6, 5, 6, 5, 0, 4, 1, 2, 3, 5, 7, 4, 0, 0, 2, 7, 0, 8, 4, 0, 5, 2, 4, 2, 8, 2, 5, 0, 4, 2, 3, 2, 3, 6, 0, 5, 4, 7, 1, 3, 5, 6, 8, 4, 3, 2, 0, 1, 8, 3, 3, 8, 8, 6, 8, 5, 4, 8, 0, 2, 7, 3, 4, 0, 5, 7, 8, 7, 5, 3, 1, 0, 8, 0, 5, 2, 3, 4, 8, 3, 3, 5, 8, 0, 8, 2, 7, 8, 0, 1, 7, 8, 5, 4, 1, 8, 8, 1, 1, 3, 2]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8, 2, 2, 8, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 150/2000 [00:02<00:27, 66.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 2, 8, 2, 2, 8, 2, 2]\n",
      "global memory:  [2, 8, 4, 4, 8, 5, 4, 4, 6, 8, 8, 3, 7, 8, 8, 0, 5, 3, 6, 2, 8, 5, 8, 6, 0, 0, 6, 8, 0, 4, 0, 3, 6, 0, 8, 5, 8, 7, 6, 7, 6, 7, 0, 8, 4, 3, 0, 0, 8, 2, 3, 6, 2, 6, 4, 3, 6, 8, 3, 6, 4, 7, 6, 8, 8, 8, 4, 5, 8, 7, 2, 0, 2, 8, 8, 3, 2, 5, 0, 5, 8, 8, 8, 7, 8, 7, 4, 5, 5, 8, 5, 5, 6, 2, 4, 7, 7, 8, 5, 0, 8, 8, 8, 0, 2, 1, 5, 8, 8, 1, 1, 8, 8, 4, 0, 2, 2, 4, 4, 4, 8, 4, 0, 4, 3, 6, 1, 5, 0, 5, 0, 4, 7, 7, 3, 0, 1, 3, 6, 8, 6, 7, 8, 2, 5, 1, 5, 4, 5, 3, 6, 7, 1, 2, 5, 1, 4, 4, 4, 7, 7, 7, 6, 1, 3, 8, 6, 6, 8, 5, 1, 7, 8, 8, 8, 4, 3, 6, 1, 8, 8, 3, 8, 5, 2, 3, 1, 6, 6, 8, 3, 4, 4, 8, 4, 8, 8, 8, 2, 7, 3, 8, 2, 1, 2, 2, 5, 4, 0, 4, 1, 0, 8, 2, 8, 1, 0, 5, 8, 6, 3, 6, 4, 2, 8, 5, 1, 5, 4, 4, 7, 5, 0, 8, 2, 0, 8, 6, 1, 7, 8, 8, 7, 3, 0, 8, 6, 0, 6, 5, 6, 8, 8, 8, 0, 3, 5, 0, 8, 8, 4, 4, 5, 7, 5, 5, 1, 7, 8, 6, 3, 8, 6, 0, 0, 6, 7, 1, 6, 0, 0, 0, 2, 2, 7, 8, 3, 4, 2, 3, 7, 4, 1, 0, 8, 7, 7, 3, 2, 8, 6, 6, 2, 2, 0, 1, 6, 0, 6, 3, 8, 8, 1, 2, 4, 0, 2, 3, 7, 5, 3, 8, 7, 7, 8, 7, 1, 8, 4, 6, 6, 6, 8, 1, 7, 2, 6, 1, 7, 2, 7, 8, 7, 5, 0, 8, 8, 5, 8, 7, 3, 8, 4, 1, 5, 1, 8, 5, 6, 3, 1, 0, 3, 2, 1, 2, 2, 0, 6, 2, 1, 7, 1, 1, 7, 8, 8, 8, 0, 6, 6, 5, 6, 7, 3, 8, 3, 8, 5, 6, 5, 3, 6, 2, 0, 5, 2, 8, 2, 8, 6, 4, 8, 8, 1, 8, 8, 4, 4, 5, 8, 8, 5, 3, 4, 2, 2, 0, 1, 8, 4, 8, 2, 7, 4, 2, 1, 0, 6, 6, 3, 5, 6, 7, 2, 5, 0, 8, 7, 6, 4, 4, 3, 2, 3, 7, 0, 3, 1, 8, 0, 8, 5, 4, 8, 8, 5, 8, 0, 4, 0, 2, 8, 8, 5, 3, 3, 4, 3, 2, 8, 3, 0, 8, 4, 4, 8, 6, 8, 4, 3, 0, 8, 4, 7, 5, 7, 1, 8, 2, 0, 2, 4, 1, 4, 8, 8, 0, 0, 5, 8, 3, 7, 5, 0, 8, 1, 1, 8, 8, 0, 8, 5, 7, 2, 5, 0, 4, 8, 8, 0, 0, 0, 8, 5, 8, 7, 4, 8, 8, 5, 4, 2, 8, 7, 8, 2, 2, 5, 5, 5, 8, 7, 3, 2, 6, 6, 3, 4, 6, 8, 2, 2, 3, 4, 8, 4, 6, 4, 8, 3, 8, 3, 8, 7, 0, 3, 8, 1, 4, 8]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "Policy Actions - No Epsilon\n",
      "[8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]\n",
      "global memory:  [3, 4, 4, 8, 4, 8, 5, 5, 1, 8, 6, 1, 3, 2, 3, 8, 4, 1, 1, 1, 8, 8, 8, 8, 8, 4, 8, 6, 1, 2, 2, 3, 6, 7, 5, 6, 7, 8, 6, 3, 0, 3, 2, 2, 2, 7, 3, 6, 4, 4, 6, 2, 0, 7, 8, 4, 3, 3, 0, 6, 8, 8, 8, 8, 4, 0, 6, 1, 7, 6, 6, 3, 8, 5, 4, 7, 8, 4, 4, 1, 5, 6, 7, 1, 2, 7, 5, 7, 2, 6, 8, 8, 0, 1, 8, 0, 3, 8, 1, 8, 8, 8, 7, 5, 4, 7, 6, 7, 5, 7, 0, 1, 4, 1, 8, 8, 5, 6, 1, 1, 5, 7, 3, 4, 3, 1, 7, 2, 6, 6, 4, 7, 8, 8, 8, 6, 0, 1, 0, 1, 6, 7, 0, 8, 5, 5, 5, 8, 7, 0, 6, 1, 1, 6, 6, 6, 5, 6, 8, 1, 6, 2, 7, 3, 5, 0, 7, 6, 6, 8, 8, 8, 1, 7, 8, 8, 8, 8, 3, 1, 0, 8, 8, 8, 3, 6, 4, 1, 7, 2, 8, 5, 1, 7, 3, 2, 3, 4, 8, 3, 5, 8, 5, 4, 2, 0, 3, 5, 0, 6, 1, 8, 0, 5, 1, 6, 1, 4, 1, 2, 5, 7, 3, 2, 6, 6, 5, 5, 8, 2, 5, 3, 0, 5, 5, 6, 0, 7, 1, 8, 8, 4, 8, 7, 3, 2, 4, 1, 8, 0, 8, 1, 1, 3, 4, 8, 8, 1, 7, 6, 4, 7, 2, 8, 5, 0, 6, 8, 1, 0, 2, 5, 8, 5, 1, 7, 8, 5, 8, 6, 4, 5, 3, 2, 8, 8, 1, 8, 0, 3, 4, 5, 8, 4, 2, 1, 2, 2, 3, 5, 5, 8, 4, 1, 0, 4, 8, 8, 8, 3, 7, 2, 7, 0, 0, 6, 1, 3, 2, 8, 8, 0, 6, 8, 7, 6, 3, 8, 2, 2, 6, 4, 0, 1, 7, 3, 4, 6, 8, 4, 8, 2, 6, 6, 0, 8, 0, 5, 3, 4, 3, 1, 7, 7, 4, 3, 7, 8, 3, 2, 8, 7, 5, 2, 0, 0, 2, 8, 8, 8, 1, 0, 5, 0, 6, 4, 4, 6, 7, 1, 6, 4, 0, 4, 4, 7, 5, 7, 5, 8, 6, 4, 0, 2, 4, 1, 5, 5, 3, 5, 0, 2, 6, 0, 6, 3, 4, 6, 8, 8, 2, 8, 6, 8, 5, 5, 4, 6, 4, 2, 6, 8, 5, 8, 8, 5, 8, 5, 8, 4, 5, 4, 8, 4, 1, 7, 2, 1, 2, 4, 1, 8, 3, 6, 0, 8, 5, 8, 3, 5, 1, 8, 8, 8, 8, 2, 1, 1, 5, 7, 2, 3, 4, 3, 7, 2, 8, 5, 1, 8, 5, 6, 1, 3, 8, 3, 8, 8, 8, 6, 7, 2, 5, 3, 8, 6, 7, 1, 2, 5, 4, 2, 7, 4, 8, 4, 6, 5, 4, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 163/2000 [00:02<00:27, 66.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1]\n",
      "global memory:  [6, 1, 1, 5, 7, 5, 3, 0, 4, 1, 1, 1, 6, 4, 6, 6, 5, 5, 4, 8, 1, 3, 3, 8, 1, 1, 6, 4, 5, 8, 6, 6, 2, 8, 0, 6, 0, 1, 7, 6, 0, 3, 8, 1, 4, 8, 2, 4, 2, 4, 2, 2, 8, 0, 4, 8, 5, 1, 1, 1, 2, 1, 6, 4, 3, 6, 6, 0, 4, 1, 5, 4, 7, 7, 5, 4, 8, 0, 5, 0, 7, 4, 6, 6, 8, 5, 3, 8, 8, 6, 8, 8, 3, 2, 3, 6, 2, 7, 4, 5, 2, 8, 2, 1, 4, 2, 8, 3, 8, 8, 5, 7, 4, 4, 8, 1, 5, 3, 6, 1, 3, 8, 8, 3, 0, 8, 0, 2, 0, 8, 6, 0, 7, 7, 4, 8, 6, 2, 3, 0, 7, 5, 2, 1, 8, 0, 4, 6, 8, 7, 5, 1, 8, 3, 5, 7, 4, 3, 4, 0, 0, 7, 4, 7, 6, 4, 0, 7, 8, 5, 4, 1, 6, 4, 5, 4, 5, 1, 2, 8, 7, 6, 0, 3, 3, 7, 0, 3, 0, 3, 2, 2, 3, 0, 3, 1, 3, 0, 3, 0, 8, 7, 6, 2, 8, 8, 3, 7, 2, 4, 2, 0, 7, 8, 6, 2, 1, 7, 4, 6, 0, 2, 7, 7, 7, 5, 8, 4, 2, 0, 8, 8, 3, 7, 7, 4, 0, 1, 8, 3, 7, 8, 0, 8, 8, 8, 7, 4, 5, 4, 0, 8, 7, 8, 1, 8, 1, 7, 1, 3, 5, 5, 7, 4, 6, 2, 6, 7, 8, 3, 2, 7, 8, 5, 7, 6, 5, 1, 2, 0, 5, 4, 5, 6, 8, 7, 3, 8, 2, 2, 2, 8, 6, 8, 7, 2, 8, 3, 5, 8, 8, 6, 6, 7]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 183/2000 [00:02<00:26, 67.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1]\n",
      "global memory:  [1, 1, 3, 7, 3, 1, 5, 2, 8, 0, 5, 2, 1, 4, 7, 3, 3, 6, 7, 2, 2, 4, 3, 0, 4, 6, 7, 5, 1, 7, 7, 1, 1, 6, 2, 0, 2, 6, 6, 4, 5, 8, 3, 2, 8, 7, 0, 1, 2, 4, 3, 6, 0, 3, 2, 4, 8, 1, 3, 3, 6, 1, 1, 5, 2, 2, 2, 7, 3, 0, 5, 8, 8, 3, 2, 6, 5, 0, 2, 8, 3, 7, 3, 0, 0, 4, 0, 3, 5, 3, 3, 8, 7, 6, 8, 3, 6, 6, 5, 8, 1, 6, 1, 0, 6, 4, 5, 4, 0, 7, 6, 2, 1, 8, 2, 7, 5, 4, 6, 1, 2, 2, 2, 3, 5, 5, 6, 1, 5, 2, 2, 6, 8, 0, 5, 0, 1, 0, 3, 5, 5, 0, 0, 6, 6, 4, 2, 2, 1, 4, 6, 1, 5, 3, 4, 3, 5, 1, 0, 2, 5, 2, 4, 3, 3, 5, 2, 6, 2, 8, 1, 3, 5, 1, 8, 8, 6, 3, 6, 3, 8, 8, 3, 4, 1, 4, 0, 8, 1, 1, 5, 5, 5, 2, 3, 1, 8, 7, 8, 3, 5, 3, 3, 0, 2, 0, 4, 6, 8, 0, 0, 1, 4, 6, 7, 1, 0, 3, 4, 4, 2, 7, 4, 7, 4, 3, 3, 3, 3, 8, 4, 3, 6, 2, 0, 3, 2, 1, 3, 2, 1, 7, 7, 2, 4, 1, 1, 3, 5, 3, 4, 3, 3, 8, 5, 0, 3, 2, 3, 1, 6, 4, 4, 4, 0, 6, 5, 8, 4, 3, 1, 7, 0, 3, 2, 2, 3, 2, 8, 3, 1, 5, 6, 6, 6, 8, 7, 2, 0, 1, 3, 0, 0, 4, 0, 0, 8, 5, 6, 3, 7, 7, 1, 3, 7, 8, 0, 8, 8, 7, 5, 0, 5, 0, 0, 8, 5, 7, 7, 0, 6, 2, 2, 4, 6, 6, 6, 2, 5, 4, 8, 8, 5, 5, 5, 5, 2, 5, 0, 3, 6, 7, 3, 7, 2, 1, 0, 0, 2, 0, 0, 5, 2, 0, 7, 0, 3, 0, 2, 7, 6, 6, 5, 0, 8, 6, 8, 3, 6, 7, 4, 5, 1, 8, 1, 0, 4, 2, 5, 0, 7, 5, 5, 7, 5, 7, 6, 8, 7, 7, 6, 5, 8, 6, 2, 6, 7, 7, 0, 5, 8, 4, 5, 0, 1, 0, 1, 6, 8, 6, 0, 4, 5, 5, 8]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1]\n",
      "global memory:  [3, 8, 1, 3, 7, 4, 1, 2, 4, 5, 8, 3, 6, 0, 5, 6, 3, 1, 7, 6, 6, 3, 3, 6, 7, 4, 5, 5, 5, 7, 6, 1, 4, 4, 5, 3, 8, 1, 7, 3, 0, 2, 3, 7, 5, 3, 3, 3, 8, 0, 3, 0, 2, 8, 0, 3, 4, 3, 4, 7, 3, 5, 3, 1, 4, 2, 1, 3, 1, 8, 1, 2, 5, 7, 5, 4, 7, 7, 1, 3, 0, 4, 6, 8, 1, 1, 8, 4, 3, 3, 2, 2, 3, 4, 7, 0, 3, 2, 4, 6, 3, 5, 3, 8, 7, 7, 5, 6, 2, 2, 8, 1, 6, 3, 2, 3, 3, 6, 7, 7, 4, 4, 5, 3, 3, 3, 2, 5, 8, 8, 7, 0, 3, 7, 1, 3, 4, 3, 3, 7, 4, 3, 2, 8, 8, 7, 8, 3, 8, 4, 4, 5, 5, 7, 3, 3, 2, 3, 3, 1, 6, 0, 8, 3, 8, 8, 6, 8, 7, 4, 5, 8, 8, 8, 8, 1, 5, 4, 5, 1, 2, 7, 8, 2, 3, 7, 5, 5, 6, 5, 1, 5, 5, 7, 3, 7]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 5]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 5]\n",
      "global memory:  [3, 2, 1, 6, 3, 4, 3, 1, 0, 3, 3, 7, 6, 1, 3, 5, 5, 1, 5, 7, 3, 4, 6, 5, 8, 5, 0, 1, 3, 6, 7, 1, 6, 7, 6, 3, 3, 7, 4, 6, 5, 8, 0, 2, 4, 0, 2, 6, 4, 2, 3, 3, 4, 3, 1, 7, 8, 3, 5, 4, 8, 6, 2, 7, 0, 3, 3, 1, 1, 5, 2, 5, 2, 4, 0, 1, 6, 2, 8, 3, 3, 6, 7, 7, 1, 7, 1, 6, 7, 1, 1, 3, 3, 3, 4, 4, 5, 7, 4, 4, 1, 3, 0, 8, 4, 5, 3, 5, 3, 1, 7, 3, 5, 2, 7, 3, 3, 1, 6, 6, 2, 6, 1, 1, 1, 1, 4, 4, 6, 8, 5, 2, 5, 4, 6, 3, 8, 3, 1, 3, 8, 3, 8, 5, 8, 6, 1, 5, 8, 3, 2, 3, 2, 5, 6, 4, 2, 0, 2, 3, 3, 8, 2, 0, 5, 3, 2, 1, 2, 0, 7, 7, 7, 7, 4, 7, 4, 6, 3, 2, 6, 0, 3, 4, 3, 7, 5, 5, 4, 5, 3, 0, 4, 7]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 214/2000 [00:03<00:25, 69.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "global memory:  [4, 0, 3, 4, 6, 3, 3, 8, 8, 2, 8, 0, 8, 3, 5, 4, 4, 2, 7, 3, 6, 0, 2, 7, 5, 3, 5, 3, 3, 8, 8, 5, 3, 5, 0, 5, 7, 3, 2, 5, 3, 4, 4, 3, 2, 1, 2, 4, 1, 7, 3, 3, 4, 3, 8, 7, 3, 7, 6, 1, 3, 1, 8, 5, 0, 7, 7, 0, 5, 0, 5, 5, 6, 2, 3, 6, 2, 6, 7, 8, 5, 8, 8, 4, 8, 8, 1, 2, 1, 3, 1, 6, 8, 5, 8, 8, 8, 6, 8, 2, 1, 5, 7, 6, 2, 4, 3, 0, 2, 5, 0, 3, 8, 4, 8, 1, 2, 4, 5, 0, 6, 5, 5, 3, 4, 6, 8, 8, 1, 3, 3, 8, 7, 6, 1, 0, 2, 4, 3, 1, 2, 3, 0, 6, 3, 4, 2, 2, 2, 3, 0, 1, 1, 4, 3, 7, 2, 4, 4, 1, 4, 3, 0, 1, 8, 2, 3, 6, 7, 2, 5, 0, 7, 3, 6, 4, 3, 0, 8, 4, 5, 3, 1, 8, 2, 1, 3, 3, 8, 5, 8, 7, 3, 3, 2, 3, 1, 3, 3, 7, 3, 3, 1, 3, 8, 0, 1, 6, 2, 1, 3, 3, 3, 5, 5, 8, 0, 2, 6, 3, 0, 3, 7, 5, 3, 3, 7, 7, 3, 3, 3, 7, 4, 3, 3, 0, 8, 6, 8, 2, 4, 7, 7, 4, 8, 5, 5, 3, 7, 7, 0, 3, 3, 0, 6, 7, 1, 3, 0]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "global memory:  [2, 2, 7, 5, 3, 3, 2, 4, 6, 7, 3, 3, 6, 6, 2, 8, 3, 3, 7, 3, 3, 2, 0, 7, 7, 4, 7, 2, 4, 7, 3, 2, 1, 0, 6, 0, 0, 3, 3, 0, 3, 2, 0, 4, 7, 7, 8, 3, 6, 3, 3, 5, 6, 4, 5, 3, 3, 3, 6, 7, 0, 6, 2, 5, 8, 4, 8, 7, 1, 5, 7, 4, 2, 6, 0, 4, 2, 4, 3, 1, 0, 0, 3, 8, 5, 1, 1, 7, 5, 8, 5, 6, 3, 0, 3, 7, 0, 0, 3, 8, 6, 1, 3, 7, 0, 4, 3, 8, 8, 3, 8, 2, 3, 4, 3, 2, 8, 6, 4, 0, 8, 6, 6, 2, 8, 7, 5, 4, 6, 5, 8, 7, 7, 0, 5, 8, 3, 7, 0, 4, 3, 0, 7, 5, 6, 6, 1, 2, 5, 6, 4, 0, 5, 4, 4, 3, 0, 1, 4, 7, 5, 3, 5, 2, 3, 7, 0, 5, 5, 2, 7, 3, 4, 6, 7, 8, 3, 0, 2, 6, 1, 1, 6, 8, 0, 3, 6, 5, 0, 5, 8, 5, 8, 0, 1, 3, 2, 5, 6, 5, 3, 6, 0, 6, 4, 6, 6, 6, 4, 7, 5, 4, 5, 4, 8, 6, 6, 4, 3, 4, 1, 8, 0, 3, 4, 5, 2, 3, 5, 5, 3, 1, 2, 1, 2, 4, 5, 5, 3, 2, 2, 8, 6, 3, 2, 7, 2, 8, 4, 2, 0, 6, 0, 5, 3, 2, 7, 1, 0, 3, 1, 4, 3, 3, 8, 0, 8, 3, 8, 8, 5, 4, 1, 0, 8, 1, 2, 3, 3, 1, 7, 7, 5, 1, 1, 6, 5, 2, 0, 8, 6, 5, 1, 4, 7, 7]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 231/2000 [00:03<00:25, 69.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "global memory:  [2, 4, 5, 5, 8, 6, 7, 3, 1, 3, 2, 3, 8, 6, 4, 5, 4, 7, 5, 4, 8, 2, 3, 8, 6, 0, 7, 1, 8, 0, 5, 4, 0, 1, 3, 4, 3, 6, 2, 1, 6, 8, 6, 3, 6, 3, 7, 7, 3, 3, 4, 0, 3, 6, 8, 8, 5, 6, 8, 7, 1, 6, 4, 8, 5, 5, 0, 5, 1, 1, 4, 0, 3, 3, 3, 3, 4, 8, 7, 8, 4, 3, 2, 5, 3, 3, 6, 7, 2, 4, 2, 8, 3, 8, 8, 0, 1, 7, 4, 3, 0, 3, 5, 1, 0, 3, 2, 6, 6, 4, 1, 4, 8, 2, 5, 3, 3, 4, 4, 6, 2, 3, 2, 3, 8, 8, 7, 5, 4, 0, 1, 3, 6, 3, 7, 4, 8, 6, 1, 8, 0, 5, 0, 2, 2, 3, 6, 2, 7, 0, 1, 6, 5, 8, 1, 3, 0, 2, 1, 2, 2, 7, 5, 7, 0, 6, 8, 2, 2, 8, 2, 6, 3, 2, 5, 7, 4, 0, 6, 7, 0, 5, 5, 2, 4, 6, 5, 3, 6, 8, 6, 1, 5, 3, 3, 8, 5, 8, 3, 5, 1, 2, 2, 2, 6, 7, 2, 8, 5, 5, 5, 1, 7, 2, 7, 5, 3, 8, 0, 3, 3, 3, 3, 6, 3, 3, 3, 3, 8, 3, 6, 5, 6, 1, 0, 4, 4, 3, 1, 3, 0, 7, 8, 3, 8, 0, 4, 3, 1, 1, 3, 0, 8, 5, 5, 5, 5, 1, 5, 6, 6, 8, 6, 7, 3, 6, 8, 8, 5, 2, 7, 0, 6, 6, 7, 7, 1, 1, 7, 2, 8, 7, 1, 0, 7, 6, 2, 5, 7, 0, 7, 5, 5, 2, 4, 3, 2, 7, 3, 1, 6, 3, 6, 4, 1, 1, 8, 4, 6, 3, 8, 0, 7, 5, 8, 7, 6, 6, 8, 7, 0, 1, 5, 5, 6, 5, 7, 0]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Policy Actions - No Epsilon\n",
      "[3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "global memory:  [3, 3, 7, 3, 4, 3, 3, 1, 5, 8, 2, 2, 0, 8, 5, 2, 7, 8, 4, 8, 7, 0, 8, 0, 4, 5, 8, 6, 5, 6, 0, 5, 3, 3, 2, 1, 4, 4, 3, 8, 5, 3, 8, 3, 1, 1, 6, 6, 1, 0, 3, 3, 3, 7, 2, 8, 2, 6, 5, 8, 3, 3, 2, 3, 3, 2, 3, 3, 8, 2, 4, 8, 2, 8, 3, 0, 3, 5, 2, 1, 3, 3, 7, 5, 1, 3, 8, 0, 3, 5, 0, 7, 8, 7, 6, 3, 4, 5, 5, 2, 4, 8, 4, 0, 3, 3, 0, 3, 3, 3, 8, 8, 3, 8, 3, 7, 4, 7, 6, 2, 2, 5, 0, 5, 4, 3, 6, 5, 3, 3, 8, 6, 5, 3, 8, 7, 0, 7, 5, 2, 6, 3, 8, 3, 2, 1, 3, 1, 4, 4, 8, 2, 1, 6, 3, 6, 8, 6, 0, 0, 2, 4, 8, 5, 5, 5, 7, 2, 2, 6, 6, 1, 4, 5, 7, 0, 6, 1, 6, 6, 8, 8, 1, 5, 6, 8, 2, 5, 4, 6, 6, 1, 8, 4, 3, 0, 5, 6, 2, 4, 8, 2, 8, 0, 5, 2, 6, 6, 8, 2, 5, 5, 4, 7, 1, 5, 5, 5, 1, 2, 4, 5, 3, 4, 3, 7, 3, 1, 4, 8, 1, 0, 4, 3, 4, 3, 2, 2, 5, 3, 7, 8, 0, 8, 2, 2, 7, 0, 2, 2, 2, 3, 2, 0, 0, 2, 1, 3, 7, 2, 2, 2, 3, 6, 8, 2, 3, 5, 6, 2, 8, 6, 2, 1, 2, 5, 2, 1, 5, 3, 3, 3, 5, 3, 4, 5, 3, 0, 5, 0]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 251/2000 [00:03<00:24, 71.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "global memory:  [1, 3, 3, 1, 3, 3, 3, 2, 5, 6, 5, 4, 1, 8, 8, 1, 5, 3, 7, 5, 3, 0, 5, 0, 6, 1, 8, 2, 6, 3, 5, 0, 1, 7, 2, 0, 2, 6, 4, 1, 0, 3, 5, 2, 0, 1, 5, 6, 7, 3, 4, 3, 2, 3, 8, 5, 2, 4, 0, 2, 2, 7, 0, 1, 4, 4, 3, 3, 1, 4, 8, 2, 5, 7, 6, 0, 2, 4, 4, 1, 4, 5, 4, 5, 5, 6, 2, 2, 5, 2, 2, 0, 3, 3, 5, 6, 6, 6, 1, 0, 2, 1, 7, 2, 0, 0, 6, 8, 5, 7, 2, 0, 2, 6, 1, 0, 3, 5, 4, 3, 3, 6, 2, 4, 4, 8, 2, 8, 5, 2, 7, 3, 2, 0, 3, 6, 7, 4, 3, 3, 8, 3, 2, 8, 2, 6, 7, 2, 6, 1, 7, 0, 2, 5, 5, 2, 2, 0, 2, 2, 3, 5, 2, 5, 2, 1, 1, 0, 0, 2, 8, 6, 3, 2, 2, 8, 1, 0, 3, 3, 2, 6, 2, 2, 1, 5, 3, 0, 3, 7, 4, 4, 0, 7, 8, 1, 7, 8, 4, 3, 0, 3, 6, 4, 6, 0, 3, 3, 4, 5, 5, 7, 3, 5, 4, 5, 1, 7, 5, 7]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "global memory:  [4, 2, 0, 6, 8, 2, 1, 4, 8, 0, 5, 8, 8, 4, 4, 2, 3, 0, 2, 7, 2, 8, 8, 3, 1, 1, 5, 8, 3, 1, 2, 6, 0, 3, 1, 4, 0, 5, 4, 3, 1, 7, 7, 5, 4, 8, 5, 4, 8, 2, 2, 1, 2, 0, 7, 3, 2, 1, 7, 7, 3, 7, 7, 2, 7, 8, 0, 1, 0, 7, 4, 2, 5, 8, 0, 5, 4, 3, 1, 5, 8, 5, 5, 2, 7, 7, 1, 0, 6, 5, 2, 1, 2, 7, 4, 5, 7, 8, 5, 7, 6, 6, 5, 5, 5, 2, 4, 5, 7, 6, 1, 3, 5, 3, 0, 4, 0, 2, 3, 1, 8, 6, 5, 5, 0, 3, 6, 3, 3, 0, 3, 0, 6, 5, 1, 0, 3, 7, 2, 1, 1, 5, 2, 8, 3, 6, 7, 5, 4, 2, 3, 2, 4, 3, 3, 1, 0, 8, 8, 3, 8, 3, 6, 5, 7, 3, 7, 3, 2, 8, 5, 8, 0, 0, 3, 4, 8, 3, 3, 3, 0, 3, 3, 8, 3, 1, 6, 3, 3, 1, 8, 6, 2, 4, 5, 8, 3, 0, 1, 2, 2, 8, 6, 2, 2, 1, 1, 1, 5, 5, 4, 3, 7, 3, 3, 5, 0, 7, 8, 5, 3, 3, 8, 2, 2, 5, 2, 2, 2, 8, 2, 5, 1, 1, 2, 2, 2, 2, 6, 3, 8, 0, 2, 4, 7, 1, 2, 7, 1, 8, 5, 8, 5, 8, 1, 8, 6, 3, 8, 8, 8, 4, 5, 0, 5, 5, 8, 0, 8, 6, 2, 2, 5, 0, 1, 1, 4, 3, 1, 3, 1, 1, 7, 3, 4]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 270/2000 [00:03<00:24, 71.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "global memory:  [3, 4, 7, 2, 6, 3, 6, 4, 8, 2, 7, 0, 5, 2, 2, 4, 8, 1, 2, 4, 8, 5, 1, 3, 2, 3, 0, 5, 1, 4, 5, 5, 0, 7, 8, 2, 4, 4, 3, 6, 3, 2, 2, 7, 2, 2, 4, 0, 0, 7, 8, 8, 6, 1, 1, 1, 1, 0, 3, 5, 3, 2, 3, 2, 3, 2, 5, 7, 4, 3, 3, 6, 2, 5, 3, 8, 3, 0, 7, 0, 3, 5, 2, 5, 5, 8, 3, 2, 8, 3, 8, 5, 5, 2, 4, 5, 0, 4, 6, 2, 5, 6, 3, 2, 3, 7, 3, 4, 3, 1, 2, 4, 7, 0, 8, 2, 2, 5, 7, 7, 0, 1, 0, 1, 5, 7, 5, 8, 5, 7, 3, 2, 3, 7, 6, 8, 2, 7, 6, 1, 1, 3, 7, 6, 6, 1, 1, 2, 4, 4, 6, 4, 6, 0, 1, 2, 6, 1, 5, 7, 0, 5, 3, 3, 3, 6, 1, 4, 2, 0, 5, 1, 6, 4, 4, 4, 5, 4, 5, 7, 2, 7, 2, 4, 1, 7, 2, 3, 2, 3, 3, 6, 2, 2, 2, 2, 6, 8, 6, 1, 7, 1, 2, 5, 1, 1, 5, 1, 1, 6, 1, 8, 2, 7, 7, 0, 1, 1, 3, 2, 2, 0, 2, 6, 0, 2, 1, 5, 3, 5, 0, 8, 3, 2, 2, 8, 3, 3, 2, 5, 2, 0, 3, 6, 0, 3, 2, 2, 5, 8, 0, 2]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n",
      "global memory:  [7, 7, 0, 1, 1, 2, 8, 1, 3, 8, 8, 1, 1, 5, 4, 3, 7, 0, 5, 2, 2, 0, 6, 0, 3, 7, 8, 1, 1, 8, 2, 4, 8, 8, 1, 4, 1, 7, 6, 0, 1, 8, 5, 6, 3, 8, 8, 0, 2, 1, 0, 2, 1, 0, 3, 4, 8, 7, 6, 4, 1, 5, 1, 3, 4, 0, 7, 1, 5, 6, 7, 5, 0, 8, 0, 1, 0, 2, 3, 2, 3, 2, 4, 6, 8, 2, 5, 7, 1, 3, 2, 1, 2, 8, 1, 2, 3, 2, 8, 5, 7, 1, 2, 3, 4, 2, 1, 5, 2, 6, 5, 1, 6, 3, 0, 2, 2, 4, 0, 2, 4, 2, 3, 1, 3, 5, 1, 2, 4, 8, 0, 2, 1, 2, 6, 2, 0, 3, 1, 4, 3, 5, 6, 2, 8, 4, 2, 1, 0, 8, 2, 6, 5, 0, 6, 2, 7, 6, 1, 7, 7, 2, 5, 0, 7, 0, 5, 6, 0, 8, 8, 3, 1, 1, 2, 1, 1, 5, 1, 7, 1, 5, 8, 6, 7, 1, 5, 4, 1, 8, 5, 1, 0, 2, 1, 2, 8, 2, 3, 6, 7, 1, 5, 8, 2, 8, 8, 2, 2, 6, 4, 1, 4, 1, 1, 0, 3, 6, 8, 8, 8, 8, 2, 1, 1, 0, 5, 3, 4, 1, 6, 7, 1, 1, 5, 5, 0, 3, 6, 2, 2, 1, 1, 4, 5, 3, 1, 5, 8, 1, 7, 2, 8, 2, 6, 0, 1, 6, 0, 1, 3, 2, 4, 1, 0, 7, 5, 7, 1, 4, 2, 2, 1, 2, 1, 3, 2, 3, 7, 2, 5, 2, 2, 6, 2, 2, 3, 5, 2, 2, 2, 4, 0, 3, 0, 2, 1, 2, 2, 2, 2, 2, 2, 0, 8, 8, 1, 5, 2, 5, 8, 1, 3, 0, 8, 0, 2, 3, 2, 4, 2, 4, 3, 3, 6, 6, 6, 7, 0, 2, 2, 8, 7, 3, 6, 8, 3, 1, 2, 7, 1, 1, 3, 4, 7, 8, 0, 1, 1, 2, 0, 0, 1, 6, 1, 7, 8, 1, 3, 1, 7, 1, 6, 3, 2, 2, 0, 2, 4, 4, 4, 3, 5, 8, 1, 3, 5, 1, 3, 2, 7, 1, 4, 2, 4, 2, 6, 4, 2, 2, 8, 8, 5, 4, 6, 5, 4, 8]\n",
      "Policy Actions - No Epsilon\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-56972085e344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m             action = agent.predict_action(state, \n\u001b[1;32m     54\u001b[0m                                           \u001b[0mnum_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                                           epsilon_stop_episode)\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0;31m# take a step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;31m# Note: action is not one-hot yet - it's a scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-371c0234e9fa>\u001b[0m in \u001b[0;36mpredict_action\u001b[0;34m(self, state, episode, episode_stop, epsilon_start, epsilon_end)\u001b[0m\n\u001b[1;32m     71\u001b[0m         action_distribution = self.session.run(\n\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         )#[0]\n\u001b[1;32m     75\u001b[0m \u001b[0;31m#       print('action dist',action_distribution)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# def main():\n",
    "# Configure Settings\n",
    "total_episodes = 2000\n",
    "epsilon_start = 1.0\n",
    "epsilon_end = 0.001\n",
    "epsilon_stop_episode = 0.6*total_episodes#3000\n",
    "BATCH_SIZE = 10 # this is the number of episodes generated before we train\n",
    "MAX_EP_LENGTH = 199 #Fixed by env in Open AI Gym (we think)\n",
    "render_start = False #-1\n",
    "should_render = False # !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "LEARNING_RATE = 1e-3\n",
    "HIDDEN_SIZE = 16\n",
    "\n",
    "# env = gym.make('CartPole-v0')\n",
    "# state_size = env.observation_space.shape[0]  # 4 for CartPole-v0\n",
    "# num_actions = env.action_space.n  # 2 for CartPole-v0\n",
    "env = FAE.FlyerAgentEnv()\n",
    "state_size = 4  \n",
    "num_actions = 9\n",
    "\n",
    "solved = False\n",
    "batch_flag = False\n",
    "num_episodes = 0\n",
    "\n",
    "with tf.Session() as session:\n",
    "    agent = PGAgent(session=session, state_size=state_size,\n",
    "      num_actions=num_actions,\n",
    "                    hidden_size=HIDDEN_SIZE, learning_rate = LEARNING_RATE)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "\n",
    "    episode_rewards = []\n",
    "    episode_terminal = [] # 1 for success, -1 for failure (o.b.)\n",
    "    episode_steps = []\n",
    "    episode_maxs = []\n",
    "    batch_losses = []\n",
    "\n",
    "    global_memory = Memory()\n",
    "    steps = 0 # total number of steps in all episodes\n",
    "    for i in tqdm.tqdm(range(total_episodes)): # multiple episode loop\n",
    "        num_episodes += 1\n",
    "        state = env.reset()\n",
    "        episode_reward = 0.0 # cumulative sum of all rewards in episode\n",
    "        episode_history = EpisodeHistory()\n",
    "        epsilon_percentage = min(i/float(\n",
    "          epsilon_stop_episode), 1.0)\n",
    "        steps_this_ep = 0\n",
    "        terminal = False\n",
    "        j = 0 # num steps in episode\n",
    "        while (j < MAX_EP_LENGTH) and (not terminal): # play single episode ------------------\n",
    "        #for j in range(MAX_EP_LENGTH):\n",
    "            j += 1\n",
    "            # figure out next action\n",
    "            action = agent.predict_action(state, \n",
    "                                          num_episodes,\n",
    "                                          epsilon_stop_episode)\n",
    "            # take a step\n",
    "            # Note: action is not one-hot yet - it's a scalar\n",
    "            state_prime, reward, terminal, _ = env.step(action)\n",
    "            \n",
    "            if (render_start > 0 and i > \n",
    "              render_start and should_render) \\\n",
    "                or (solved and should_render):\n",
    "                env.render()\n",
    "            episode_history.add_to_history(\n",
    "                state, action, reward, state_prime)\n",
    "            episode_reward += reward\n",
    "            steps += 1\n",
    "            steps_this_ep += 1\n",
    "            # advance the state\n",
    "            state = state_prime\n",
    "            \n",
    "#         print('number of steps in episode', j)  \n",
    "        episode_history.discounted_returns = discount_rewards(episode_history.rewards)\n",
    "        \n",
    "#         # this is a modification that attempts to enhance the rewards for \"good\" episodes\n",
    "#         # it doesn't seem to hurt - need more experimentation to know if it helps\n",
    "#         for nn in range(len(episode_history.discounted_returns)):\n",
    "#             episode_history.discounted_returns[nn] *= (1+(steps_this_ep/MAX_EP_LENGTH))**2\n",
    "\n",
    "        global_memory.add_episode(episode_history)\n",
    "        episode_rewards.append(episode_reward)\n",
    "        # save sum of rewards, num_steps of this episode\n",
    "        episode_steps.append(steps_this_ep)\n",
    "        episode_maxs.append(max(episode_history.rewards))\n",
    "        episode_terminal.append(terminal)\n",
    "\n",
    "        # if we completed a minibatch then train\n",
    "        if np.mod(i, BATCH_SIZE) == 0:\n",
    "            agent.show_current_policy()\n",
    "            print('global memory: ',global_memory.actions)\n",
    "            feed_dict = {\n",
    "            agent.reward_input: np.array(\n",
    "              global_memory.discounted_returns),\n",
    "            agent.action_input: np.array(\n",
    "              global_memory.actions), \n",
    "            agent.state: np.array(\n",
    "              global_memory.states)}\n",
    "            _, batch_loss = session.run(\n",
    "                [agent.train_step, agent.loss],\n",
    "                  feed_dict=feed_dict)\n",
    "            batch_losses.append(batch_loss)\n",
    "            global_memory.reset_memory()            \n",
    "            agent.show_current_policy()\n",
    "            \n",
    "#             if i > 1:\n",
    "#                 batch_flag = True\n",
    "\n",
    "#         #delete this\n",
    "#         if terminal == 0 or batch_flag or num_episodes == 50:\n",
    "#             print('terminal ',terminal,' batch_flag ',batch_flag)\n",
    "#             break\n",
    "\n",
    "#         if i % 10: # show results every 10th iteration\n",
    "#             if np.mean(episode_rewards[:]) > 100.0:\n",
    "#                 solved = True\n",
    "#             else:\n",
    "#                 solved = False\n",
    "#     print('Solved:', solved, 'Mean Reward', np.mean(episode_rewards[:-100]))\n",
    "    \n",
    "    print('Num episodes:',num_episodes)\n",
    "    \n",
    "    print('Final Mean Reward - last 100', np.mean(episode_rewards[-100:-1]))\n",
    "        \n",
    "    print('Final Run - with Epsilon')\n",
    "    print(episode_history.actions)\n",
    "    \n",
    "    \n",
    "    print('Final Policy - No Epsilon')\n",
    "    env.reset()\n",
    "    e_p = 1.0 # so use end epsilon\n",
    "    for n in range(20):    # figure out next action\n",
    "        action = agent.predict_action_0ep(state)\n",
    "        # take a step\n",
    "        state_prime, reward, terminal, _ = env.step(action)\n",
    "        state = state_prime\n",
    "        print(state_prime,action,reward)  \n",
    "        # NOTE: doesn't terminate with done flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(episode_rewards,'bd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    print('Final Mean Reward - last 100', np.mean(episode_rewards[-100:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(episode_terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
